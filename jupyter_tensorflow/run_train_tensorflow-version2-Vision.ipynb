{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepLOB: Deep Convolutional Neural Networks for Limit Order Books\n",
    "\n",
    "### Authors: Zihao Zhang, Stefan Zohren and Stephen Roberts\n",
    "Oxford-Man Institute of Quantitative Finance, Department of Engineering Science, University of Oxford\n",
    "\n",
    "This jupyter notebook is used to demonstrate our recent paper [2] published in IEEE Transactions on Singal Processing. We use FI-2010 [1] dataset and present how model architecture is constructed here. \n",
    "\n",
    "### Data:\n",
    "The FI-2010 is publicly avilable and interested readers can check out their paper [1]. The dataset can be downloaded from: https://etsin.fairdata.fi/dataset/73eb48d7-4dbc-4a10-a52a-da745b47a649 \n",
    "\n",
    "Otherwise, the notebook will download the data automatically or it can be obtained from: \n",
    "\n",
    "https://drive.google.com/drive/folders/1Xen3aRid9ZZhFqJRgEMyETNazk02cNmv?usp=sharing.\n",
    "\n",
    "### References:\n",
    "[1] Ntakaris A, Magris M, Kanniainen J, Gabbouj M, Iosifidis A. Benchmark dataset for mid‚Äêprice forecasting of limit order book data with machine learning methods. Journal of Forecasting. 2018 Dec;37(8):852-66. https://arxiv.org/abs/1705.03233\n",
    "\n",
    "[2] Zhang Z, Zohren S, Roberts S. DeepLOB: Deep convolutional neural networks for limit order books. IEEE Transactions on Signal Processing. 2019 Mar 25;67(11):3001-12. https://arxiv.org/abs/1808.03668\n",
    "\n",
    "### This notebook runs on tensorflow 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data already existed.\n"
     ]
    }
   ],
   "source": [
    "# obtain data\n",
    "import os \n",
    "if not os.path.isfile('data.zip'):\n",
    "    !wget https://raw.githubusercontent.com/zcakhaa/DeepLOB-Deep-Convolutional-Neural-Networks-for-Limit-Order-Books/master/data/data.zip\n",
    "    !unzip -n data.zip\n",
    "    print('data downloaded.')\n",
    "else:\n",
    "    print('data already existed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "# limit gpu memory\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, Activation, Input, LSTM, Reshape, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# set random seeds\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "We used no auction dataset that is normalised by decimal precision approach in their work. The first 40 columns of the FI-2010 dataset are 10 levels ask and bid information for a limit order book and we only use these 40 features in our network. The last 5 columns of the FI-2010 dataset are the labels with different prediction horizons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_x(data):\n",
    "    df1 = data[:40, :].T\n",
    "    return np.array(df1)\n",
    "\n",
    "def get_label(data):\n",
    "    lob = data[-5:, :].T\n",
    "    return lob\n",
    "\n",
    "def data_classification(X, Y, T):\n",
    "    [N, D] = X.shape\n",
    "    df = np.array(X)\n",
    "    dY = np.array(Y)\n",
    "    dataY = dY[T - 1:N]\n",
    "    dataX = np.zeros((N - T + 1, T, D))\n",
    "    for i in range(T, N + 1):\n",
    "        dataX[i - T] = df[i - T:i, :]\n",
    "    return dataX.reshape(dataX.shape + (1,)), dataY\n",
    "\n",
    "def prepare_x_y(data, k, T):\n",
    "    x = prepare_x(data)\n",
    "    y = get_label(data)\n",
    "    x, y = data_classification(x, y, T=T)\n",
    "    y = y[:,k] - 1\n",
    "    y = to_categorical(y, 3)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(203701, 100, 40, 1) (203701, 3)\n",
      "(50851, 100, 40, 1) (50851, 3)\n",
      "(139488, 100, 40, 1) (139488, 3)\n"
     ]
    }
   ],
   "source": [
    "# please change the data_path to your local path\n",
    "# data_path = '/nfs/home/zihaoz/limit_order_book/data'\n",
    "\n",
    "dec_data = np.loadtxt('Train_Dst_NoAuction_DecPre_CF_7.txt')\n",
    "dec_train = dec_data[:, :int(np.floor(dec_data.shape[1] * 0.8))]\n",
    "dec_val = dec_data[:, int(np.floor(dec_data.shape[1] * 0.8)):]\n",
    "\n",
    "dec_test1 = np.loadtxt('Test_Dst_NoAuction_DecPre_CF_7.txt')\n",
    "dec_test2 = np.loadtxt('Test_Dst_NoAuction_DecPre_CF_8.txt')\n",
    "dec_test3 = np.loadtxt('Test_Dst_NoAuction_DecPre_CF_9.txt')\n",
    "dec_test = np.hstack((dec_test1, dec_test2, dec_test3))\n",
    "\n",
    "k = 4 # which prediction horizon\n",
    "T = 100 # the length of a single input\n",
    "n_hiddens = 64\n",
    "checkpoint_filepath = './model_tensorflow2/weights'\n",
    "\n",
    "trainX_CNN, trainY_CNN = prepare_x_y(dec_train, k, T)\n",
    "valX_CNN, valY_CNN = prepare_x_y(dec_val, k, T)\n",
    "testX_CNN, testY_CNN = prepare_x_y(dec_test, k, T)\n",
    "\n",
    "print(trainX_CNN.shape, trainY_CNN.shape)\n",
    "print(valX_CNN.shape, valY_CNN.shape)\n",
    "print(testX_CNN.shape, testY_CNN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "139400\r"
     ]
    }
   ],
   "source": [
    "def get_image_data(cnn_data):\n",
    "    new_x = cnn_data.copy()\n",
    "    for j in range(new_x.shape[0]):\n",
    "        x_coords = np.arange(\n",
    "            np.min(new_x[j,:,::2,0]), \n",
    "            np.max(new_x[j,:,::2,0]), \n",
    "            np.min( np.abs( np.diff( new_x[j,0,::4,0] ) ) ) #ticksize\n",
    "        )\n",
    "        new_image = np.zeros((100,len(x_coords)+1))\n",
    "        \n",
    "        for z in range(100):\n",
    "            new_image[z, np.digitize( new_x[j,z,2::4,0], x_coords )] = new_x[j,z,3::4,0] #bid prices\n",
    "            new_image[z, np.digitize( new_x[j,z,::4,0], x_coords )] = -new_x[j,z,1::4,0] #ask prices\n",
    "\n",
    "        anchor_position = np.digitize( new_x[j,-1,2,0], x_coords )\n",
    "        while anchor_position < 20:\n",
    "            new_image = np.hstack([np.zeros((100,1)),new_image])\n",
    "            anchor_position += 1\n",
    "\n",
    "        while new_image.shape[1] < anchor_position+20:\n",
    "            new_image = np.hstack([new_image,np.zeros((100,1))])\n",
    "            \n",
    "        new_x[j,:,:,0] = new_image[:,range(anchor_position-20,anchor_position+20)]\n",
    "        if j % 100 == 0:\n",
    "            print( j, end=\"\\r\")\n",
    "    return new_x\n",
    "    \n",
    "new_x_train = get_image_data(trainX_CNN)\n",
    "new_x_val = get_image_data(valX_CNN)\n",
    "new_x_test = get_image_data(testX_CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture\n",
    "\n",
    "Please find the detailed discussion of our model architecture in our paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 100, 40, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 100, 20, 32)  96          ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 100, 20, 32)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 100, 20, 32)  4128        ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 100, 20, 32)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 100, 20, 32)  4128        ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 100, 20, 32)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 100, 10, 32)  2080        ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 100, 10, 32)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 100, 10, 32)  4128        ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 100, 10, 32)  0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 100, 10, 32)  4128        ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 100, 10, 32)  0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 100, 1, 32)   10272       ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 100, 1, 32)   0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 100, 1, 32)   4128        ['leaky_re_lu_6[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 100, 1, 32)   0           ['conv2d_7[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 100, 1, 32)   4128        ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 100, 1, 32)   0           ['conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 100, 1, 64)   2112        ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 100, 1, 64)   2112        ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 100, 1, 64)   0           ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 100, 1, 32)   0           ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 100, 1, 64)   12352       ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 100, 1, 64)   20544       ['leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 100, 1, 64)   2112        ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_10[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_12[0][0]']              \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 100, 1, 64)   0           ['conv2d_13[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 100, 1, 192)  0           ['leaky_re_lu_10[0][0]',         \n",
      "                                                                  'leaky_re_lu_12[0][0]',         \n",
      "                                                                  'leaky_re_lu_13[0][0]']         \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 100, 192)     0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 100, 192)     0           ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 64)           65792       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 3)            195         ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 142,435\n",
      "Trainable params: 142,435\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jefferythewind/anaconda3/envs/ml/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "def create_deeplob(T, NF, number_of_lstm):\n",
    "    input_lmd = Input(shape=(T, NF, 1))\n",
    "    \n",
    "    # build the convolutional block\n",
    "    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(input_lmd)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\n",
    "    conv_first1 = Conv2D(32, (1, 2), strides=(1, 2))(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "\n",
    "    conv_first1 = Conv2D(32, (1, 10))(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    conv_first1 = Conv2D(32, (4, 1), padding='same')(conv_first1)\n",
    "    conv_first1 = keras.layers.LeakyReLU(alpha=0.01)(conv_first1)\n",
    "    \n",
    "    # build the inception module\n",
    "    convsecond_1 = Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n",
    "    convsecond_1 = Conv2D(64, (3, 1), padding='same')(convsecond_1)\n",
    "    convsecond_1 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_1)\n",
    "\n",
    "    convsecond_2 = Conv2D(64, (1, 1), padding='same')(conv_first1)\n",
    "    convsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n",
    "    convsecond_2 = Conv2D(64, (5, 1), padding='same')(convsecond_2)\n",
    "    convsecond_2 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_2)\n",
    "\n",
    "    convsecond_3 = MaxPooling2D((3, 1), strides=(1, 1), padding='same')(conv_first1)\n",
    "    convsecond_3 = Conv2D(64, (1, 1), padding='same')(convsecond_3)\n",
    "    convsecond_3 = keras.layers.LeakyReLU(alpha=0.01)(convsecond_3)\n",
    "    \n",
    "    convsecond_output = keras.layers.concatenate([convsecond_1, convsecond_2, convsecond_3], axis=3)\n",
    "    conv_reshape = Reshape((int(convsecond_output.shape[1]), int(convsecond_output.shape[3])))(convsecond_output)\n",
    "    conv_reshape = keras.layers.Dropout(0.2, noise_shape=(None, 1, int(conv_reshape.shape[2])))(conv_reshape, training=True)\n",
    "\n",
    "    # build the last LSTM layer\n",
    "    conv_lstm = LSTM(number_of_lstm)(conv_reshape)\n",
    "\n",
    "    # build the output layer\n",
    "    out = Dense(3, activation='softmax')(conv_lstm)\n",
    "    model = Model(inputs=input_lmd, outputs=out)\n",
    "    adam = keras.optimizers.Adam(lr=0.0001)\n",
    "    model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "deeplob = create_deeplob(trainX_CNN.shape[1], trainX_CNN.shape[2], n_hiddens)\n",
    "deeplob.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1592/1592 - 29s - loss: 0.8065 - accuracy: 0.6246 - val_loss: 0.6922 - val_accuracy: 0.7190 - 29s/epoch - 18ms/step\n",
      "Epoch 2/400\n",
      "1592/1592 - 24s - loss: 0.5709 - accuracy: 0.7726 - val_loss: 0.6253 - val_accuracy: 0.7500 - 24s/epoch - 15ms/step\n",
      "Epoch 3/400\n",
      "1592/1592 - 25s - loss: 0.5235 - accuracy: 0.7944 - val_loss: 0.5779 - val_accuracy: 0.7753 - 25s/epoch - 15ms/step\n",
      "Epoch 4/400\n",
      "1592/1592 - 25s - loss: 0.4965 - accuracy: 0.8077 - val_loss: 0.5471 - val_accuracy: 0.7867 - 25s/epoch - 15ms/step\n",
      "Epoch 5/400\n",
      "1592/1592 - 25s - loss: 0.4738 - accuracy: 0.8196 - val_loss: 0.5510 - val_accuracy: 0.7842 - 25s/epoch - 16ms/step\n",
      "Epoch 6/400\n",
      "1592/1592 - 25s - loss: 0.4582 - accuracy: 0.8272 - val_loss: 0.5096 - val_accuracy: 0.8085 - 25s/epoch - 16ms/step\n",
      "Epoch 7/400\n",
      "1592/1592 - 25s - loss: 0.4420 - accuracy: 0.8339 - val_loss: 0.4923 - val_accuracy: 0.8166 - 25s/epoch - 16ms/step\n",
      "Epoch 8/400\n",
      "1592/1592 - 25s - loss: 0.4292 - accuracy: 0.8400 - val_loss: 0.4848 - val_accuracy: 0.8211 - 25s/epoch - 16ms/step\n",
      "Epoch 9/400\n",
      "1592/1592 - 25s - loss: 0.4194 - accuracy: 0.8448 - val_loss: 0.4721 - val_accuracy: 0.8218 - 25s/epoch - 16ms/step\n",
      "Epoch 10/400\n",
      "1592/1592 - 25s - loss: 0.4040 - accuracy: 0.8512 - val_loss: 0.4516 - val_accuracy: 0.8330 - 25s/epoch - 16ms/step\n",
      "Epoch 11/400\n",
      "1592/1592 - 25s - loss: 0.3906 - accuracy: 0.8565 - val_loss: 0.4339 - val_accuracy: 0.8392 - 25s/epoch - 16ms/step\n",
      "Epoch 12/400\n",
      "1592/1592 - 25s - loss: 0.3814 - accuracy: 0.8607 - val_loss: 0.4248 - val_accuracy: 0.8440 - 25s/epoch - 16ms/step\n",
      "Epoch 13/400\n",
      "1592/1592 - 25s - loss: 0.3708 - accuracy: 0.8650 - val_loss: 0.4406 - val_accuracy: 0.8365 - 25s/epoch - 16ms/step\n",
      "Epoch 14/400\n",
      "1592/1592 - 25s - loss: 0.3657 - accuracy: 0.8670 - val_loss: 0.4381 - val_accuracy: 0.8385 - 25s/epoch - 16ms/step\n",
      "Epoch 15/400\n",
      "1592/1592 - 25s - loss: 0.3591 - accuracy: 0.8695 - val_loss: 0.4446 - val_accuracy: 0.8349 - 25s/epoch - 16ms/step\n",
      "Epoch 16/400\n",
      "1592/1592 - 25s - loss: 0.3267 - accuracy: 0.8822 - val_loss: 0.3763 - val_accuracy: 0.8613 - 25s/epoch - 16ms/step\n",
      "Epoch 22/400\n",
      "1592/1592 - 25s - loss: 0.3211 - accuracy: 0.8844 - val_loss: 0.4471 - val_accuracy: 0.8333 - 25s/epoch - 16ms/step\n",
      "Epoch 23/400\n",
      "1592/1592 - 25s - loss: 0.3172 - accuracy: 0.8859 - val_loss: 0.3665 - val_accuracy: 0.8668 - 25s/epoch - 16ms/step\n",
      "Epoch 24/400\n",
      "1592/1592 - 25s - loss: 0.3149 - accuracy: 0.8868 - val_loss: 0.3570 - val_accuracy: 0.8692 - 25s/epoch - 16ms/step\n",
      "Epoch 25/400\n",
      "1592/1592 - 25s - loss: 0.3102 - accuracy: 0.8889 - val_loss: 0.3676 - val_accuracy: 0.8646 - 25s/epoch - 16ms/step\n",
      "Epoch 26/400\n",
      "1592/1592 - 25s - loss: 0.3072 - accuracy: 0.8899 - val_loss: 0.3720 - val_accuracy: 0.8647 - 25s/epoch - 16ms/step\n",
      "Epoch 27/400\n",
      "1592/1592 - 25s - loss: 0.3045 - accuracy: 0.8914 - val_loss: 0.3711 - val_accuracy: 0.8639 - 25s/epoch - 16ms/step\n",
      "Epoch 28/400\n",
      "1592/1592 - 25s - loss: 0.3005 - accuracy: 0.8925 - val_loss: 0.3455 - val_accuracy: 0.8744 - 25s/epoch - 16ms/step\n",
      "Epoch 29/400\n",
      "1592/1592 - 25s - loss: 0.3226 - accuracy: 0.8828 - val_loss: 0.3846 - val_accuracy: 0.8576 - 25s/epoch - 16ms/step\n",
      "Epoch 30/400\n",
      "1592/1592 - 25s - loss: 0.2977 - accuracy: 0.8940 - val_loss: 0.3531 - val_accuracy: 0.8722 - 25s/epoch - 16ms/step\n",
      "Epoch 31/400\n",
      "1592/1592 - 25s - loss: 0.2920 - accuracy: 0.8958 - val_loss: 0.3345 - val_accuracy: 0.8791 - 25s/epoch - 16ms/step\n",
      "Epoch 32/400\n",
      "1592/1592 - 25s - loss: 0.2918 - accuracy: 0.8965 - val_loss: 0.3453 - val_accuracy: 0.8769 - 25s/epoch - 16ms/step\n",
      "Epoch 33/400\n",
      "1592/1592 - 25s - loss: 0.2873 - accuracy: 0.8980 - val_loss: 0.3417 - val_accuracy: 0.8757 - 25s/epoch - 16ms/step\n",
      "Epoch 34/400\n",
      "1592/1592 - 25s - loss: 0.2865 - accuracy: 0.8981 - val_loss: 0.3411 - val_accuracy: 0.8781 - 25s/epoch - 16ms/step\n",
      "Epoch 35/400\n",
      "1592/1592 - 25s - loss: 0.2835 - accuracy: 0.8994 - val_loss: 0.3418 - val_accuracy: 0.8779 - 25s/epoch - 16ms/step\n",
      "Epoch 36/400\n",
      "1592/1592 - 25s - loss: 0.2813 - accuracy: 0.8997 - val_loss: 0.3373 - val_accuracy: 0.8789 - 25s/epoch - 16ms/step\n",
      "Epoch 37/400\n",
      "1592/1592 - 25s - loss: 0.2785 - accuracy: 0.9013 - val_loss: 0.3432 - val_accuracy: 0.8782 - 25s/epoch - 16ms/step\n",
      "Epoch 38/400\n",
      "1592/1592 - 25s - loss: 0.2770 - accuracy: 0.9016 - val_loss: 0.3269 - val_accuracy: 0.8822 - 25s/epoch - 16ms/step\n",
      "Epoch 39/400\n",
      "1592/1592 - 25s - loss: 0.2763 - accuracy: 0.9022 - val_loss: 0.3373 - val_accuracy: 0.8800 - 25s/epoch - 16ms/step\n",
      "Epoch 40/400\n",
      "1592/1592 - 25s - loss: 0.2748 - accuracy: 0.9029 - val_loss: 0.3380 - val_accuracy: 0.8785 - 25s/epoch - 16ms/step\n",
      "Epoch 41/400\n",
      "1592/1592 - 25s - loss: 0.2710 - accuracy: 0.9040 - val_loss: 0.3246 - val_accuracy: 0.8843 - 25s/epoch - 16ms/step\n",
      "Epoch 42/400\n",
      "1592/1592 - 25s - loss: 0.2707 - accuracy: 0.9040 - val_loss: 0.3284 - val_accuracy: 0.8826 - 25s/epoch - 16ms/step\n",
      "Epoch 43/400\n",
      "1592/1592 - 25s - loss: 0.2689 - accuracy: 0.9046 - val_loss: 0.3329 - val_accuracy: 0.8812 - 25s/epoch - 16ms/step\n",
      "Epoch 44/400\n",
      "1592/1592 - 25s - loss: 0.2658 - accuracy: 0.9060 - val_loss: 0.3183 - val_accuracy: 0.8866 - 25s/epoch - 16ms/step\n",
      "Epoch 45/400\n",
      "1592/1592 - 25s - loss: 0.2666 - accuracy: 0.9056 - val_loss: 0.3701 - val_accuracy: 0.8677 - 25s/epoch - 16ms/step\n",
      "Epoch 46/400\n",
      "1592/1592 - 25s - loss: 0.2648 - accuracy: 0.9060 - val_loss: 0.3284 - val_accuracy: 0.8824 - 25s/epoch - 16ms/step\n",
      "Epoch 47/400\n",
      "1592/1592 - 25s - loss: 0.2628 - accuracy: 0.9067 - val_loss: 0.4058 - val_accuracy: 0.8492 - 25s/epoch - 16ms/step\n",
      "Epoch 48/400\n",
      "1592/1592 - 25s - loss: 0.2608 - accuracy: 0.9079 - val_loss: 0.3420 - val_accuracy: 0.8760 - 25s/epoch - 16ms/step\n",
      "Epoch 49/400\n",
      "1592/1592 - 25s - loss: 0.2585 - accuracy: 0.9083 - val_loss: 0.3146 - val_accuracy: 0.8883 - 25s/epoch - 16ms/step\n",
      "Epoch 50/400\n",
      "1592/1592 - 25s - loss: 0.2583 - accuracy: 0.9092 - val_loss: 0.3354 - val_accuracy: 0.8808 - 25s/epoch - 16ms/step\n",
      "Epoch 51/400\n",
      "1592/1592 - 25s - loss: 0.2677 - accuracy: 0.9046 - val_loss: 0.3388 - val_accuracy: 0.8801 - 25s/epoch - 16ms/step\n",
      "Epoch 52/400\n",
      "1592/1592 - 25s - loss: 0.2559 - accuracy: 0.9098 - val_loss: 0.3170 - val_accuracy: 0.8883 - 25s/epoch - 16ms/step\n",
      "Epoch 53/400\n",
      "1592/1592 - 25s - loss: 0.2530 - accuracy: 0.9109 - val_loss: 0.3242 - val_accuracy: 0.8830 - 25s/epoch - 16ms/step\n",
      "Epoch 54/400\n",
      "1592/1592 - 25s - loss: 0.2535 - accuracy: 0.9107 - val_loss: 0.3261 - val_accuracy: 0.8835 - 25s/epoch - 16ms/step\n",
      "Epoch 55/400\n",
      "1592/1592 - 25s - loss: 0.2511 - accuracy: 0.9114 - val_loss: 0.3296 - val_accuracy: 0.8806 - 25s/epoch - 16ms/step\n",
      "Epoch 56/400\n",
      "1592/1592 - 25s - loss: 0.2495 - accuracy: 0.9119 - val_loss: 0.3259 - val_accuracy: 0.8845 - 25s/epoch - 16ms/step\n",
      "Epoch 57/400\n",
      "1592/1592 - 25s - loss: 0.2479 - accuracy: 0.9128 - val_loss: 0.3199 - val_accuracy: 0.8856 - 25s/epoch - 16ms/step\n",
      "Epoch 58/400\n",
      "1592/1592 - 25s - loss: 0.2473 - accuracy: 0.9129 - val_loss: 0.3131 - val_accuracy: 0.8868 - 25s/epoch - 16ms/step\n",
      "Epoch 59/400\n",
      "1592/1592 - 25s - loss: 0.2460 - accuracy: 0.9133 - val_loss: 0.3091 - val_accuracy: 0.8886 - 25s/epoch - 16ms/step\n",
      "Epoch 60/400\n",
      "1592/1592 - 25s - loss: 0.2441 - accuracy: 0.9138 - val_loss: 0.3070 - val_accuracy: 0.8901 - 25s/epoch - 16ms/step\n",
      "Epoch 61/400\n",
      "1592/1592 - 25s - loss: 0.2624 - accuracy: 0.9061 - val_loss: 0.3169 - val_accuracy: 0.8859 - 25s/epoch - 16ms/step\n",
      "Epoch 62/400\n",
      "1592/1592 - 25s - loss: 0.2428 - accuracy: 0.9140 - val_loss: 0.3116 - val_accuracy: 0.8897 - 25s/epoch - 16ms/step\n",
      "Epoch 63/400\n",
      "1592/1592 - 25s - loss: 0.2415 - accuracy: 0.9152 - val_loss: 0.3116 - val_accuracy: 0.8884 - 25s/epoch - 16ms/step\n",
      "Epoch 64/400\n",
      "1592/1592 - 25s - loss: 0.2411 - accuracy: 0.9146 - val_loss: 0.3010 - val_accuracy: 0.8924 - 25s/epoch - 16ms/step\n",
      "Epoch 65/400\n",
      "1592/1592 - 25s - loss: 0.2406 - accuracy: 0.9152 - val_loss: 0.3714 - val_accuracy: 0.8667 - 25s/epoch - 16ms/step\n",
      "Epoch 66/400\n",
      "1592/1592 - 25s - loss: 0.2386 - accuracy: 0.9156 - val_loss: 0.3243 - val_accuracy: 0.8848 - 25s/epoch - 16ms/step\n",
      "Epoch 67/400\n",
      "1592/1592 - 25s - loss: 0.2384 - accuracy: 0.9160 - val_loss: 0.3207 - val_accuracy: 0.8890 - 25s/epoch - 16ms/step\n",
      "Epoch 68/400\n",
      "1592/1592 - 25s - loss: 0.2377 - accuracy: 0.9159 - val_loss: 0.3208 - val_accuracy: 0.8847 - 25s/epoch - 16ms/step\n",
      "Epoch 69/400\n",
      "1592/1592 - 25s - loss: 0.2366 - accuracy: 0.9167 - val_loss: 0.3059 - val_accuracy: 0.8910 - 25s/epoch - 16ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/400\n",
      "1592/1592 - 25s - loss: 0.2356 - accuracy: 0.9167 - val_loss: 0.3126 - val_accuracy: 0.8886 - 25s/epoch - 16ms/step\n",
      "Epoch 71/400\n",
      "1592/1592 - 25s - loss: 0.2339 - accuracy: 0.9174 - val_loss: 0.3125 - val_accuracy: 0.8907 - 25s/epoch - 16ms/step\n",
      "Epoch 72/400\n",
      "1592/1592 - 25s - loss: 0.2330 - accuracy: 0.9174 - val_loss: 0.3155 - val_accuracy: 0.8870 - 25s/epoch - 16ms/step\n",
      "Epoch 73/400\n",
      "1592/1592 - 25s - loss: 0.2340 - accuracy: 0.9174 - val_loss: 0.3209 - val_accuracy: 0.8860 - 25s/epoch - 16ms/step\n",
      "Epoch 74/400\n",
      "1592/1592 - 25s - loss: 0.2311 - accuracy: 0.9184 - val_loss: 0.3039 - val_accuracy: 0.8910 - 25s/epoch - 16ms/step\n",
      "Epoch 75/400\n",
      "1592/1592 - 25s - loss: 0.2303 - accuracy: 0.9190 - val_loss: 0.3157 - val_accuracy: 0.8860 - 25s/epoch - 16ms/step\n",
      "Epoch 76/400\n",
      "1592/1592 - 25s - loss: 0.2313 - accuracy: 0.9184 - val_loss: 0.3110 - val_accuracy: 0.8889 - 25s/epoch - 16ms/step\n",
      "Epoch 77/400\n",
      "1592/1592 - 25s - loss: 0.2860 - accuracy: 0.8945 - val_loss: 0.3053 - val_accuracy: 0.8905 - 25s/epoch - 16ms/step\n",
      "Epoch 78/400\n",
      "1592/1592 - 25s - loss: 0.2283 - accuracy: 0.9194 - val_loss: 0.3327 - val_accuracy: 0.8810 - 25s/epoch - 16ms/step\n",
      "Epoch 79/400\n",
      "1592/1592 - 25s - loss: 0.2284 - accuracy: 0.9192 - val_loss: 0.3046 - val_accuracy: 0.8902 - 25s/epoch - 16ms/step\n",
      "Epoch 80/400\n",
      "1592/1592 - 25s - loss: 0.2274 - accuracy: 0.9195 - val_loss: 0.3333 - val_accuracy: 0.8818 - 25s/epoch - 16ms/step\n",
      "Epoch 81/400\n",
      "1592/1592 - 25s - loss: 0.2272 - accuracy: 0.9199 - val_loss: 0.3192 - val_accuracy: 0.8866 - 25s/epoch - 16ms/step\n",
      "Epoch 82/400\n",
      "1592/1592 - 25s - loss: 0.2269 - accuracy: 0.9195 - val_loss: 0.3076 - val_accuracy: 0.8899 - 25s/epoch - 16ms/step\n",
      "Epoch 83/400\n",
      "1592/1592 - 25s - loss: 0.2249 - accuracy: 0.9204 - val_loss: 0.3064 - val_accuracy: 0.8893 - 25s/epoch - 16ms/step\n",
      "Epoch 84/400\n",
      "1592/1592 - 25s - loss: 0.2258 - accuracy: 0.9199 - val_loss: 0.3117 - val_accuracy: 0.8896 - 25s/epoch - 16ms/step\n",
      "Epoch 85/400\n",
      "1592/1592 - 25s - loss: 0.2237 - accuracy: 0.9208 - val_loss: 0.3134 - val_accuracy: 0.8866 - 25s/epoch - 16ms/step\n",
      "Epoch 86/400\n",
      "1592/1592 - 25s - loss: 0.2236 - accuracy: 0.9209 - val_loss: 0.3125 - val_accuracy: 0.8900 - 25s/epoch - 16ms/step\n",
      "Epoch 87/400\n",
      "1592/1592 - 25s - loss: 0.2224 - accuracy: 0.9212 - val_loss: 0.3288 - val_accuracy: 0.8808 - 25s/epoch - 16ms/step\n",
      "Epoch 88/400\n",
      "1592/1592 - 25s - loss: 0.2220 - accuracy: 0.9214 - val_loss: 0.3074 - val_accuracy: 0.8912 - 25s/epoch - 16ms/step\n",
      "Epoch 89/400\n",
      "1592/1592 - 25s - loss: 0.2216 - accuracy: 0.9215 - val_loss: 0.3056 - val_accuracy: 0.8922 - 25s/epoch - 16ms/step\n",
      "Epoch 90/400\n",
      "1592/1592 - 25s - loss: 0.2204 - accuracy: 0.9215 - val_loss: 0.3050 - val_accuracy: 0.8905 - 25s/epoch - 16ms/step\n",
      "Epoch 91/400\n",
      "1592/1592 - 25s - loss: 0.2199 - accuracy: 0.9222 - val_loss: 0.3097 - val_accuracy: 0.8907 - 25s/epoch - 16ms/step\n",
      "Epoch 92/400\n",
      "1592/1592 - 25s - loss: 0.2192 - accuracy: 0.9223 - val_loss: 0.3143 - val_accuracy: 0.8879 - 25s/epoch - 16ms/step\n",
      "Epoch 93/400\n",
      "1592/1592 - 25s - loss: 0.2193 - accuracy: 0.9223 - val_loss: 0.3060 - val_accuracy: 0.8918 - 25s/epoch - 16ms/step\n",
      "Epoch 94/400\n",
      "1592/1592 - 25s - loss: 0.2174 - accuracy: 0.9228 - val_loss: 0.3154 - val_accuracy: 0.8903 - 25s/epoch - 16ms/step\n",
      "Epoch 95/400\n",
      "1592/1592 - 25s - loss: 0.2172 - accuracy: 0.9227 - val_loss: 0.3096 - val_accuracy: 0.8894 - 25s/epoch - 16ms/step\n",
      "Epoch 96/400\n",
      "1592/1592 - 25s - loss: 0.2161 - accuracy: 0.9233 - val_loss: 0.3329 - val_accuracy: 0.8857 - 25s/epoch - 16ms/step\n",
      "Epoch 97/400\n",
      "1592/1592 - 25s - loss: 0.2172 - accuracy: 0.9227 - val_loss: 0.3111 - val_accuracy: 0.8896 - 25s/epoch - 16ms/step\n",
      "Epoch 98/400\n",
      "1592/1592 - 25s - loss: 0.2161 - accuracy: 0.9232 - val_loss: 0.3086 - val_accuracy: 0.8896 - 25s/epoch - 16ms/step\n",
      "Epoch 99/400\n",
      "1592/1592 - 25s - loss: 0.2147 - accuracy: 0.9238 - val_loss: 0.3041 - val_accuracy: 0.8915 - 25s/epoch - 16ms/step\n",
      "Epoch 100/400\n",
      "1592/1592 - 25s - loss: 0.2144 - accuracy: 0.9241 - val_loss: 0.3168 - val_accuracy: 0.8874 - 25s/epoch - 16ms/step\n",
      "Epoch 101/400\n",
      "1592/1592 - 25s - loss: 0.2137 - accuracy: 0.9239 - val_loss: 0.3122 - val_accuracy: 0.8903 - 25s/epoch - 16ms/step\n",
      "Epoch 102/400\n",
      "1592/1592 - 25s - loss: 0.2130 - accuracy: 0.9242 - val_loss: 0.3140 - val_accuracy: 0.8908 - 25s/epoch - 16ms/step\n",
      "Epoch 103/400\n",
      "1592/1592 - 25s - loss: 0.2129 - accuracy: 0.9242 - val_loss: 0.3282 - val_accuracy: 0.8828 - 25s/epoch - 16ms/step\n",
      "Epoch 104/400\n",
      "1592/1592 - 25s - loss: 0.2157 - accuracy: 0.9234 - val_loss: 0.3198 - val_accuracy: 0.8887 - 25s/epoch - 16ms/step\n",
      "Epoch 105/400\n",
      "1592/1592 - 25s - loss: 0.2118 - accuracy: 0.9245 - val_loss: 0.3181 - val_accuracy: 0.8893 - 25s/epoch - 16ms/step\n",
      "Epoch 106/400\n",
      "1592/1592 - 25s - loss: 0.2098 - accuracy: 0.9254 - val_loss: 0.3132 - val_accuracy: 0.8907 - 25s/epoch - 16ms/step\n",
      "Epoch 107/400\n",
      "1592/1592 - 25s - loss: 0.2111 - accuracy: 0.9250 - val_loss: 0.3249 - val_accuracy: 0.8853 - 25s/epoch - 16ms/step\n",
      "Epoch 108/400\n",
      "1592/1592 - 25s - loss: 0.2098 - accuracy: 0.9256 - val_loss: 0.3265 - val_accuracy: 0.8845 - 25s/epoch - 16ms/step\n",
      "Epoch 109/400\n",
      "1592/1592 - 25s - loss: 0.2082 - accuracy: 0.9256 - val_loss: 0.3228 - val_accuracy: 0.8860 - 25s/epoch - 16ms/step\n",
      "Epoch 110/400\n",
      "1592/1592 - 25s - loss: 0.2085 - accuracy: 0.9259 - val_loss: 0.3251 - val_accuracy: 0.8851 - 25s/epoch - 16ms/step\n",
      "Epoch 111/400\n",
      "1592/1592 - 25s - loss: 0.2081 - accuracy: 0.9260 - val_loss: 0.3199 - val_accuracy: 0.8882 - 25s/epoch - 16ms/step\n",
      "Epoch 112/400\n",
      "1592/1592 - 25s - loss: 0.2061 - accuracy: 0.9265 - val_loss: 0.3242 - val_accuracy: 0.8867 - 25s/epoch - 16ms/step\n",
      "Epoch 113/400\n",
      "1592/1592 - 25s - loss: 0.2072 - accuracy: 0.9265 - val_loss: 0.3104 - val_accuracy: 0.8907 - 25s/epoch - 16ms/step\n",
      "Epoch 114/400\n",
      "1592/1592 - 25s - loss: 0.2059 - accuracy: 0.9265 - val_loss: 0.3216 - val_accuracy: 0.8868 - 25s/epoch - 16ms/step\n",
      "Epoch 115/400\n",
      "1592/1592 - 25s - loss: 0.2047 - accuracy: 0.9272 - val_loss: 0.3183 - val_accuracy: 0.8877 - 25s/epoch - 16ms/step\n",
      "Epoch 116/400\n",
      "1592/1592 - 25s - loss: 0.2042 - accuracy: 0.9270 - val_loss: 0.3162 - val_accuracy: 0.8904 - 25s/epoch - 16ms/step\n",
      "Epoch 117/400\n",
      "1592/1592 - 25s - loss: 0.2047 - accuracy: 0.9268 - val_loss: 0.3222 - val_accuracy: 0.8880 - 25s/epoch - 16ms/step\n",
      "Epoch 118/400\n",
      "1592/1592 - 25s - loss: 0.2027 - accuracy: 0.9279 - val_loss: 0.3189 - val_accuracy: 0.8882 - 25s/epoch - 16ms/step\n",
      "Epoch 119/400\n",
      "1592/1592 - 25s - loss: 0.2020 - accuracy: 0.9279 - val_loss: 0.3188 - val_accuracy: 0.8880 - 25s/epoch - 16ms/step\n",
      "Epoch 120/400\n",
      "1592/1592 - 25s - loss: 0.2023 - accuracy: 0.9277 - val_loss: 0.3181 - val_accuracy: 0.8902 - 25s/epoch - 16ms/step\n",
      "Epoch 121/400\n",
      "1592/1592 - 25s - loss: 0.2016 - accuracy: 0.9281 - val_loss: 0.3251 - val_accuracy: 0.8874 - 25s/epoch - 16ms/step\n",
      "Epoch 122/400\n",
      "1592/1592 - 25s - loss: 0.2003 - accuracy: 0.9282 - val_loss: 0.3187 - val_accuracy: 0.8870 - 25s/epoch - 16ms/step\n",
      "Epoch 123/400\n",
      "1592/1592 - 25s - loss: 0.2007 - accuracy: 0.9284 - val_loss: 0.3147 - val_accuracy: 0.8877 - 25s/epoch - 16ms/step\n",
      "Epoch 124/400\n",
      "1592/1592 - 25s - loss: 0.2002 - accuracy: 0.9287 - val_loss: 0.3166 - val_accuracy: 0.8860 - 25s/epoch - 16ms/step\n",
      "Epoch 125/400\n",
      "1592/1592 - 25s - loss: 0.1994 - accuracy: 0.9287 - val_loss: 0.3185 - val_accuracy: 0.8878 - 25s/epoch - 16ms/step\n",
      "Epoch 126/400\n",
      "1592/1592 - 25s - loss: 0.1980 - accuracy: 0.9293 - val_loss: 0.3301 - val_accuracy: 0.8830 - 25s/epoch - 16ms/step\n",
      "Epoch 127/400\n",
      "1592/1592 - 25s - loss: 0.1981 - accuracy: 0.9290 - val_loss: 0.3313 - val_accuracy: 0.8864 - 25s/epoch - 16ms/step\n",
      "Epoch 128/400\n",
      "1592/1592 - 25s - loss: 0.1975 - accuracy: 0.9290 - val_loss: 0.3432 - val_accuracy: 0.8791 - 25s/epoch - 16ms/step\n",
      "Epoch 129/400\n",
      "1592/1592 - 25s - loss: 0.1978 - accuracy: 0.9294 - val_loss: 0.3157 - val_accuracy: 0.8889 - 25s/epoch - 16ms/step\n",
      "Epoch 130/400\n",
      "1592/1592 - 25s - loss: 0.1978 - accuracy: 0.9294 - val_loss: 0.3231 - val_accuracy: 0.8856 - 25s/epoch - 16ms/step\n",
      "Epoch 131/400\n",
      "1592/1592 - 25s - loss: 0.1958 - accuracy: 0.9300 - val_loss: 0.3188 - val_accuracy: 0.8897 - 25s/epoch - 16ms/step\n",
      "Epoch 132/400\n",
      "1592/1592 - 25s - loss: 0.1954 - accuracy: 0.9305 - val_loss: 0.3245 - val_accuracy: 0.8846 - 25s/epoch - 16ms/step\n",
      "Epoch 133/400\n",
      "1592/1592 - 25s - loss: 0.1945 - accuracy: 0.9303 - val_loss: 0.3299 - val_accuracy: 0.8847 - 25s/epoch - 16ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 134/400\n",
      "1592/1592 - 25s - loss: 0.1945 - accuracy: 0.9307 - val_loss: 0.3229 - val_accuracy: 0.8875 - 25s/epoch - 16ms/step\n",
      "Epoch 135/400\n",
      "1592/1592 - 25s - loss: 0.1950 - accuracy: 0.9302 - val_loss: 0.3271 - val_accuracy: 0.8852 - 25s/epoch - 16ms/step\n",
      "Epoch 136/400\n",
      "1592/1592 - 25s - loss: 0.1927 - accuracy: 0.9308 - val_loss: 0.3291 - val_accuracy: 0.8872 - 25s/epoch - 16ms/step\n",
      "Epoch 137/400\n",
      "1592/1592 - 25s - loss: 0.1931 - accuracy: 0.9310 - val_loss: 0.3274 - val_accuracy: 0.8874 - 25s/epoch - 16ms/step\n",
      "Epoch 138/400\n",
      "1592/1592 - 25s - loss: 0.1920 - accuracy: 0.9315 - val_loss: 0.3338 - val_accuracy: 0.8854 - 25s/epoch - 16ms/step\n",
      "Epoch 139/400\n",
      "1592/1592 - 25s - loss: 0.1908 - accuracy: 0.9316 - val_loss: 0.3340 - val_accuracy: 0.8870 - 25s/epoch - 16ms/step\n",
      "Epoch 140/400\n",
      "1592/1592 - 25s - loss: 0.1914 - accuracy: 0.9308 - val_loss: 0.3265 - val_accuracy: 0.8873 - 25s/epoch - 16ms/step\n",
      "Epoch 141/400\n",
      "1592/1592 - 25s - loss: 0.1909 - accuracy: 0.9321 - val_loss: 0.3313 - val_accuracy: 0.8863 - 25s/epoch - 16ms/step\n",
      "Epoch 142/400\n",
      "1592/1592 - 25s - loss: 0.1891 - accuracy: 0.9320 - val_loss: 0.3375 - val_accuracy: 0.8818 - 25s/epoch - 16ms/step\n",
      "Epoch 143/400\n",
      "1592/1592 - 25s - loss: 0.1900 - accuracy: 0.9319 - val_loss: 0.3314 - val_accuracy: 0.8832 - 25s/epoch - 16ms/step\n",
      "Epoch 144/400\n",
      "1592/1592 - 25s - loss: 0.1881 - accuracy: 0.9321 - val_loss: 0.3333 - val_accuracy: 0.8869 - 25s/epoch - 16ms/step\n",
      "Epoch 145/400\n",
      "1592/1592 - 25s - loss: 0.1879 - accuracy: 0.9324 - val_loss: 0.3335 - val_accuracy: 0.8844 - 25s/epoch - 16ms/step\n",
      "Epoch 146/400\n",
      "1592/1592 - 25s - loss: 0.1883 - accuracy: 0.9324 - val_loss: 0.3305 - val_accuracy: 0.8852 - 25s/epoch - 16ms/step\n",
      "Epoch 147/400\n",
      "1592/1592 - 25s - loss: 0.1888 - accuracy: 0.9327 - val_loss: 0.3443 - val_accuracy: 0.8812 - 25s/epoch - 16ms/step\n",
      "Epoch 148/400\n",
      "1592/1592 - 25s - loss: 0.1860 - accuracy: 0.9332 - val_loss: 0.3343 - val_accuracy: 0.8869 - 25s/epoch - 16ms/step\n",
      "Epoch 149/400\n",
      "1592/1592 - 25s - loss: 0.1860 - accuracy: 0.9334 - val_loss: 0.3296 - val_accuracy: 0.8866 - 25s/epoch - 16ms/step\n",
      "Epoch 150/400\n",
      "1592/1592 - 25s - loss: 0.1854 - accuracy: 0.9331 - val_loss: 0.3495 - val_accuracy: 0.8793 - 25s/epoch - 16ms/step\n",
      "Epoch 151/400\n",
      "1592/1592 - 25s - loss: 0.1838 - accuracy: 0.9344 - val_loss: 0.3489 - val_accuracy: 0.8788 - 25s/epoch - 16ms/step\n",
      "Epoch 152/400\n",
      "1592/1592 - 25s - loss: 0.1852 - accuracy: 0.9334 - val_loss: 0.3311 - val_accuracy: 0.8877 - 25s/epoch - 16ms/step\n",
      "Epoch 153/400\n",
      "1592/1592 - 25s - loss: 0.1841 - accuracy: 0.9340 - val_loss: 0.3684 - val_accuracy: 0.8722 - 25s/epoch - 16ms/step\n",
      "Epoch 154/400\n",
      "1592/1592 - 25s - loss: 0.1838 - accuracy: 0.9341 - val_loss: 0.3517 - val_accuracy: 0.8808 - 25s/epoch - 16ms/step\n",
      "Epoch 155/400\n",
      "1592/1592 - 25s - loss: 0.1824 - accuracy: 0.9348 - val_loss: 0.3363 - val_accuracy: 0.8846 - 25s/epoch - 15ms/step\n",
      "Epoch 156/400\n",
      "1592/1592 - 25s - loss: 0.1821 - accuracy: 0.9345 - val_loss: 0.3394 - val_accuracy: 0.8816 - 25s/epoch - 16ms/step\n",
      "Epoch 157/400\n",
      "1592/1592 - 25s - loss: 0.1828 - accuracy: 0.9344 - val_loss: 0.3403 - val_accuracy: 0.8836 - 25s/epoch - 16ms/step\n",
      "Epoch 158/400\n",
      "1592/1592 - 25s - loss: 0.1823 - accuracy: 0.9339 - val_loss: 0.3331 - val_accuracy: 0.8846 - 25s/epoch - 16ms/step\n",
      "Epoch 159/400\n",
      "1592/1592 - 25s - loss: 0.1800 - accuracy: 0.9358 - val_loss: 0.3460 - val_accuracy: 0.8827 - 25s/epoch - 16ms/step\n",
      "Epoch 160/400\n",
      "1592/1592 - 25s - loss: 0.1807 - accuracy: 0.9351 - val_loss: 0.3538 - val_accuracy: 0.8789 - 25s/epoch - 16ms/step\n",
      "Epoch 161/400\n",
      "1592/1592 - 25s - loss: 0.1765 - accuracy: 0.9366 - val_loss: 0.3535 - val_accuracy: 0.8784 - 25s/epoch - 16ms/step\n",
      "Epoch 167/400\n",
      "1592/1592 - 25s - loss: 0.1769 - accuracy: 0.9363 - val_loss: 0.3495 - val_accuracy: 0.8824 - 25s/epoch - 16ms/step\n",
      "Epoch 168/400\n",
      "1592/1592 - 25s - loss: 0.1767 - accuracy: 0.9365 - val_loss: 0.3653 - val_accuracy: 0.8818 - 25s/epoch - 16ms/step\n",
      "Epoch 169/400\n",
      "1592/1592 - 25s - loss: 0.1763 - accuracy: 0.9366 - val_loss: 0.3491 - val_accuracy: 0.8811 - 25s/epoch - 16ms/step\n",
      "Epoch 170/400\n",
      "1592/1592 - 25s - loss: 0.1754 - accuracy: 0.9373 - val_loss: 0.3435 - val_accuracy: 0.8824 - 25s/epoch - 16ms/step\n",
      "Epoch 171/400\n",
      "1592/1592 - 25s - loss: 0.1743 - accuracy: 0.9374 - val_loss: 0.3568 - val_accuracy: 0.8798 - 25s/epoch - 16ms/step\n",
      "Epoch 172/400\n",
      "1592/1592 - 25s - loss: 0.1745 - accuracy: 0.9371 - val_loss: 0.3638 - val_accuracy: 0.8792 - 25s/epoch - 16ms/step\n",
      "Epoch 173/400\n",
      "1592/1592 - 25s - loss: 0.1917 - accuracy: 0.9309 - val_loss: 0.7022 - val_accuracy: 0.7304 - 25s/epoch - 16ms/step\n",
      "Epoch 174/400\n",
      "1592/1592 - 25s - loss: 0.1875 - accuracy: 0.9320 - val_loss: 0.3479 - val_accuracy: 0.8803 - 25s/epoch - 16ms/step\n",
      "Epoch 175/400\n",
      "1592/1592 - 25s - loss: 0.1734 - accuracy: 0.9375 - val_loss: 0.3502 - val_accuracy: 0.8834 - 25s/epoch - 16ms/step\n",
      "Epoch 176/400\n",
      "1592/1592 - 25s - loss: 0.1714 - accuracy: 0.9382 - val_loss: 0.3622 - val_accuracy: 0.8794 - 25s/epoch - 16ms/step\n",
      "Epoch 177/400\n",
      "1592/1592 - 25s - loss: 0.1722 - accuracy: 0.9380 - val_loss: 0.3563 - val_accuracy: 0.8803 - 25s/epoch - 16ms/step\n",
      "Epoch 178/400\n",
      "1592/1592 - 25s - loss: 0.1716 - accuracy: 0.9378 - val_loss: 0.3604 - val_accuracy: 0.8798 - 25s/epoch - 16ms/step\n",
      "Epoch 179/400\n",
      "1592/1592 - 25s - loss: 0.1707 - accuracy: 0.9380 - val_loss: 0.3544 - val_accuracy: 0.8809 - 25s/epoch - 16ms/step\n",
      "Epoch 180/400\n",
      "1592/1592 - 25s - loss: 0.1704 - accuracy: 0.9385 - val_loss: 0.3621 - val_accuracy: 0.8787 - 25s/epoch - 16ms/step\n",
      "Epoch 181/400\n",
      "1592/1592 - 25s - loss: 0.1703 - accuracy: 0.9384 - val_loss: 0.3537 - val_accuracy: 0.8820 - 25s/epoch - 16ms/step\n",
      "Epoch 182/400\n",
      "1592/1592 - 25s - loss: 0.1675 - accuracy: 0.9400 - val_loss: 0.3554 - val_accuracy: 0.8839 - 25s/epoch - 16ms/step\n",
      "Epoch 183/400\n",
      "1592/1592 - 25s - loss: 0.1691 - accuracy: 0.9390 - val_loss: 0.3606 - val_accuracy: 0.8826 - 25s/epoch - 16ms/step\n",
      "Epoch 184/400\n",
      "1592/1592 - 25s - loss: 0.1683 - accuracy: 0.9394 - val_loss: 0.3591 - val_accuracy: 0.8789 - 25s/epoch - 16ms/step\n",
      "Epoch 185/400\n",
      "1592/1592 - 25s - loss: 0.1682 - accuracy: 0.9393 - val_loss: 0.3608 - val_accuracy: 0.8818 - 25s/epoch - 16ms/step\n",
      "Epoch 186/400\n",
      "1592/1592 - 25s - loss: 0.1675 - accuracy: 0.9394 - val_loss: 0.3714 - val_accuracy: 0.8783 - 25s/epoch - 16ms/step\n",
      "Epoch 187/400\n",
      "1592/1592 - 25s - loss: 0.1668 - accuracy: 0.9399 - val_loss: 0.3674 - val_accuracy: 0.8800 - 25s/epoch - 16ms/step\n",
      "Epoch 188/400\n",
      "1592/1592 - 25s - loss: 0.1661 - accuracy: 0.9401 - val_loss: 0.3606 - val_accuracy: 0.8820 - 25s/epoch - 16ms/step\n",
      "Epoch 189/400\n",
      "1592/1592 - 25s - loss: 0.1663 - accuracy: 0.9398 - val_loss: 0.3653 - val_accuracy: 0.8806 - 25s/epoch - 16ms/step\n",
      "Epoch 190/400\n",
      "1592/1592 - 25s - loss: 0.1654 - accuracy: 0.9406 - val_loss: 0.3679 - val_accuracy: 0.8781 - 25s/epoch - 16ms/step\n",
      "Epoch 191/400\n",
      "1592/1592 - 25s - loss: 0.1653 - accuracy: 0.9400 - val_loss: 0.3829 - val_accuracy: 0.8777 - 25s/epoch - 16ms/step\n",
      "Epoch 192/400\n",
      "1592/1592 - 25s - loss: 0.1651 - accuracy: 0.9402 - val_loss: 0.3683 - val_accuracy: 0.8825 - 25s/epoch - 16ms/step\n",
      "Epoch 193/400\n",
      "1592/1592 - 25s - loss: 0.1638 - accuracy: 0.9411 - val_loss: 0.3724 - val_accuracy: 0.8798 - 25s/epoch - 16ms/step\n",
      "Epoch 194/400\n",
      "1592/1592 - 25s - loss: 0.1639 - accuracy: 0.9406 - val_loss: 0.3738 - val_accuracy: 0.8802 - 25s/epoch - 16ms/step\n",
      "Epoch 195/400\n",
      "1592/1592 - 25s - loss: 0.1624 - accuracy: 0.9412 - val_loss: 0.3736 - val_accuracy: 0.8807 - 25s/epoch - 16ms/step\n",
      "Epoch 196/400\n",
      "1592/1592 - 25s - loss: 0.1629 - accuracy: 0.9410 - val_loss: 0.3758 - val_accuracy: 0.8796 - 25s/epoch - 16ms/step\n",
      "Epoch 197/400\n",
      "1592/1592 - 25s - loss: 0.1616 - accuracy: 0.9419 - val_loss: 0.3737 - val_accuracy: 0.8769 - 25s/epoch - 16ms/step\n",
      "Epoch 198/400\n",
      "1592/1592 - 25s - loss: 0.1621 - accuracy: 0.9416 - val_loss: 0.3784 - val_accuracy: 0.8797 - 25s/epoch - 16ms/step\n",
      "Epoch 199/400\n",
      "1592/1592 - 25s - loss: 0.1607 - accuracy: 0.9418 - val_loss: 0.3878 - val_accuracy: 0.8765 - 25s/epoch - 16ms/step\n",
      "Epoch 200/400\n",
      "1592/1592 - 25s - loss: 0.1610 - accuracy: 0.9418 - val_loss: 0.3739 - val_accuracy: 0.8759 - 25s/epoch - 16ms/step\n",
      "Epoch 201/400\n",
      "1592/1592 - 25s - loss: 0.1608 - accuracy: 0.9419 - val_loss: 0.3696 - val_accuracy: 0.8802 - 25s/epoch - 16ms/step\n",
      "Epoch 202/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1592/1592 - 25s - loss: 0.1596 - accuracy: 0.9424 - val_loss: 0.3732 - val_accuracy: 0.8781 - 25s/epoch - 16ms/step\n",
      "Epoch 203/400\n",
      "1592/1592 - 25s - loss: 0.1593 - accuracy: 0.9423 - val_loss: 0.3860 - val_accuracy: 0.8743 - 25s/epoch - 16ms/step\n",
      "Epoch 204/400\n",
      "1592/1592 - 25s - loss: 0.1584 - accuracy: 0.9422 - val_loss: 0.3827 - val_accuracy: 0.8788 - 25s/epoch - 16ms/step\n",
      "Epoch 205/400\n",
      "1592/1592 - 25s - loss: 0.1583 - accuracy: 0.9431 - val_loss: 0.3909 - val_accuracy: 0.8766 - 25s/epoch - 16ms/step\n",
      "Epoch 206/400\n",
      "1592/1592 - 25s - loss: 0.1579 - accuracy: 0.9430 - val_loss: 0.3815 - val_accuracy: 0.8772 - 25s/epoch - 16ms/step\n",
      "Epoch 207/400\n",
      "1592/1592 - 25s - loss: 0.1565 - accuracy: 0.9433 - val_loss: 0.3881 - val_accuracy: 0.8765 - 25s/epoch - 16ms/step\n",
      "Epoch 208/400\n",
      "1592/1592 - 25s - loss: 0.1566 - accuracy: 0.9437 - val_loss: 0.3794 - val_accuracy: 0.8797 - 25s/epoch - 16ms/step\n",
      "Epoch 209/400\n",
      "1592/1592 - 25s - loss: 0.1569 - accuracy: 0.9434 - val_loss: 0.3917 - val_accuracy: 0.8743 - 25s/epoch - 16ms/step\n",
      "Epoch 210/400\n",
      "1592/1592 - 25s - loss: 0.1555 - accuracy: 0.9440 - val_loss: 0.3934 - val_accuracy: 0.8771 - 25s/epoch - 16ms/step\n",
      "Epoch 211/400\n",
      "1592/1592 - 25s - loss: 0.1563 - accuracy: 0.9437 - val_loss: 0.3838 - val_accuracy: 0.8749 - 25s/epoch - 16ms/step\n",
      "Epoch 212/400\n",
      "1592/1592 - 25s - loss: 0.1553 - accuracy: 0.9437 - val_loss: 0.3845 - val_accuracy: 0.8760 - 25s/epoch - 16ms/step\n",
      "Epoch 213/400\n",
      "1592/1592 - 25s - loss: 0.1553 - accuracy: 0.9439 - val_loss: 0.3837 - val_accuracy: 0.8795 - 25s/epoch - 16ms/step\n",
      "Epoch 214/400\n",
      "1592/1592 - 25s - loss: 0.1543 - accuracy: 0.9442 - val_loss: 0.3806 - val_accuracy: 0.8764 - 25s/epoch - 16ms/step\n",
      "Epoch 215/400\n",
      "1592/1592 - 25s - loss: 0.1538 - accuracy: 0.9442 - val_loss: 0.3844 - val_accuracy: 0.8791 - 25s/epoch - 16ms/step\n",
      "Epoch 216/400\n",
      "1592/1592 - 25s - loss: 0.1539 - accuracy: 0.9443 - val_loss: 0.3893 - val_accuracy: 0.8761 - 25s/epoch - 16ms/step\n",
      "Epoch 217/400\n",
      "1592/1592 - 25s - loss: 0.1526 - accuracy: 0.9447 - val_loss: 0.3930 - val_accuracy: 0.8739 - 25s/epoch - 16ms/step\n",
      "Epoch 218/400\n",
      "1592/1592 - 25s - loss: 0.1534 - accuracy: 0.9443 - val_loss: 0.4393 - val_accuracy: 0.8592 - 25s/epoch - 16ms/step\n",
      "Epoch 219/400\n",
      "1592/1592 - 25s - loss: 0.1522 - accuracy: 0.9444 - val_loss: 0.4023 - val_accuracy: 0.8729 - 25s/epoch - 16ms/step\n",
      "Epoch 220/400\n",
      "1592/1592 - 25s - loss: 0.1511 - accuracy: 0.9456 - val_loss: 0.3933 - val_accuracy: 0.8749 - 25s/epoch - 16ms/step\n",
      "Epoch 221/400\n",
      "1592/1592 - 25s - loss: 0.1500 - accuracy: 0.9454 - val_loss: 0.3967 - val_accuracy: 0.8755 - 25s/epoch - 16ms/step\n",
      "Epoch 222/400\n",
      "1592/1592 - 25s - loss: 0.1504 - accuracy: 0.9454 - val_loss: 0.4040 - val_accuracy: 0.8751 - 25s/epoch - 16ms/step\n",
      "Epoch 223/400\n",
      "1592/1592 - 25s - loss: 0.1505 - accuracy: 0.9453 - val_loss: 0.3887 - val_accuracy: 0.8782 - 25s/epoch - 16ms/step\n",
      "Epoch 224/400\n",
      "1592/1592 - 25s - loss: 0.1502 - accuracy: 0.9452 - val_loss: 0.3987 - val_accuracy: 0.8742 - 25s/epoch - 16ms/step\n",
      "Epoch 225/400\n",
      "1592/1592 - 25s - loss: 0.1502 - accuracy: 0.9454 - val_loss: 0.3950 - val_accuracy: 0.8759 - 25s/epoch - 16ms/step\n",
      "Epoch 226/400\n",
      "1592/1592 - 25s - loss: 0.1493 - accuracy: 0.9461 - val_loss: 0.4010 - val_accuracy: 0.8762 - 25s/epoch - 16ms/step\n",
      "Epoch 227/400\n",
      "1592/1592 - 25s - loss: 0.1490 - accuracy: 0.9459 - val_loss: 0.4031 - val_accuracy: 0.8757 - 25s/epoch - 16ms/step\n",
      "Epoch 228/400\n",
      "1592/1592 - 25s - loss: 0.1483 - accuracy: 0.9461 - val_loss: 0.4042 - val_accuracy: 0.8753 - 25s/epoch - 16ms/step\n",
      "Epoch 229/400\n",
      "1592/1592 - 25s - loss: 0.1482 - accuracy: 0.9461 - val_loss: 0.3938 - val_accuracy: 0.8783 - 25s/epoch - 16ms/step\n",
      "Epoch 230/400\n",
      "1592/1592 - 25s - loss: 0.1486 - accuracy: 0.9465 - val_loss: 0.4055 - val_accuracy: 0.8764 - 25s/epoch - 16ms/step\n",
      "Epoch 231/400\n",
      "1592/1592 - 25s - loss: 0.1466 - accuracy: 0.9466 - val_loss: 0.3972 - val_accuracy: 0.8737 - 25s/epoch - 16ms/step\n",
      "Epoch 232/400\n",
      "1592/1592 - 25s - loss: 0.1459 - accuracy: 0.9468 - val_loss: 0.4130 - val_accuracy: 0.8743 - 25s/epoch - 16ms/step\n",
      "Epoch 233/400\n",
      "1592/1592 - 25s - loss: 0.1460 - accuracy: 0.9470 - val_loss: 0.4169 - val_accuracy: 0.8696 - 25s/epoch - 16ms/step\n",
      "Epoch 234/400\n",
      "1592/1592 - 25s - loss: 0.1458 - accuracy: 0.9472 - val_loss: 0.4059 - val_accuracy: 0.8744 - 25s/epoch - 16ms/step\n",
      "Epoch 235/400\n",
      "1592/1592 - 25s - loss: 0.1475 - accuracy: 0.9467 - val_loss: 0.4172 - val_accuracy: 0.8741 - 25s/epoch - 16ms/step\n",
      "Epoch 236/400\n",
      "1592/1592 - 25s - loss: 0.1435 - accuracy: 0.9479 - val_loss: 0.4122 - val_accuracy: 0.8716 - 25s/epoch - 16ms/step\n",
      "Epoch 237/400\n",
      "1592/1592 - 25s - loss: 0.1438 - accuracy: 0.9478 - val_loss: 0.4035 - val_accuracy: 0.8725 - 25s/epoch - 16ms/step\n",
      "Epoch 238/400\n",
      "1592/1592 - 25s - loss: 0.1436 - accuracy: 0.9483 - val_loss: 0.4072 - val_accuracy: 0.8757 - 25s/epoch - 16ms/step\n",
      "Epoch 239/400\n",
      "1592/1592 - 25s - loss: 0.1429 - accuracy: 0.9478 - val_loss: 0.4114 - val_accuracy: 0.8737 - 25s/epoch - 16ms/step\n",
      "Epoch 240/400\n",
      "1592/1592 - 25s - loss: 0.1433 - accuracy: 0.9478 - val_loss: 0.4174 - val_accuracy: 0.8700 - 25s/epoch - 16ms/step\n",
      "Epoch 241/400\n",
      "1592/1592 - 25s - loss: 0.1420 - accuracy: 0.9481 - val_loss: 0.4126 - val_accuracy: 0.8752 - 25s/epoch - 16ms/step\n",
      "Epoch 242/400\n",
      "1592/1592 - 25s - loss: 0.1424 - accuracy: 0.9481 - val_loss: 0.4132 - val_accuracy: 0.8667 - 25s/epoch - 16ms/step\n",
      "Epoch 243/400\n",
      "1592/1592 - 25s - loss: 0.1411 - accuracy: 0.9485 - val_loss: 0.4125 - val_accuracy: 0.8722 - 25s/epoch - 16ms/step\n",
      "Epoch 244/400\n",
      "1592/1592 - 25s - loss: 0.1407 - accuracy: 0.9487 - val_loss: 0.4126 - val_accuracy: 0.8745 - 25s/epoch - 16ms/step\n",
      "Epoch 245/400\n",
      "1592/1592 - 25s - loss: 0.1401 - accuracy: 0.9487 - val_loss: 0.4136 - val_accuracy: 0.8747 - 25s/epoch - 16ms/step\n",
      "Epoch 246/400\n",
      "1592/1592 - 25s - loss: 0.1400 - accuracy: 0.9492 - val_loss: 0.4173 - val_accuracy: 0.8699 - 25s/epoch - 16ms/step\n",
      "Epoch 247/400\n",
      "1592/1592 - 25s - loss: 0.1398 - accuracy: 0.9491 - val_loss: 0.4194 - val_accuracy: 0.8743 - 25s/epoch - 16ms/step\n",
      "Epoch 248/400\n",
      "1592/1592 - 25s - loss: 0.1394 - accuracy: 0.9493 - val_loss: 0.4208 - val_accuracy: 0.8709 - 25s/epoch - 16ms/step\n",
      "Epoch 249/400\n",
      "1592/1592 - 25s - loss: 0.1386 - accuracy: 0.9497 - val_loss: 0.4160 - val_accuracy: 0.8749 - 25s/epoch - 16ms/step\n",
      "Epoch 250/400\n",
      "1592/1592 - 25s - loss: 0.1388 - accuracy: 0.9495 - val_loss: 0.4227 - val_accuracy: 0.8753 - 25s/epoch - 16ms/step\n",
      "Epoch 251/400\n",
      "1592/1592 - 25s - loss: 0.1382 - accuracy: 0.9498 - val_loss: 0.4264 - val_accuracy: 0.8714 - 25s/epoch - 16ms/step\n",
      "Epoch 252/400\n",
      "1592/1592 - 25s - loss: 0.1368 - accuracy: 0.9500 - val_loss: 0.4259 - val_accuracy: 0.8752 - 25s/epoch - 16ms/step\n",
      "Epoch 253/400\n",
      "1592/1592 - 25s - loss: 0.1374 - accuracy: 0.9501 - val_loss: 0.4241 - val_accuracy: 0.8738 - 25s/epoch - 16ms/step\n",
      "Epoch 254/400\n",
      "1592/1592 - 25s - loss: 0.1367 - accuracy: 0.9505 - val_loss: 0.4398 - val_accuracy: 0.8704 - 25s/epoch - 16ms/step\n",
      "Epoch 255/400\n",
      "1592/1592 - 25s - loss: 0.1360 - accuracy: 0.9507 - val_loss: 0.4347 - val_accuracy: 0.8723 - 25s/epoch - 16ms/step\n",
      "Epoch 256/400\n",
      "1592/1592 - 25s - loss: 0.1363 - accuracy: 0.9507 - val_loss: 0.4173 - val_accuracy: 0.8748 - 25s/epoch - 16ms/step\n",
      "Epoch 257/400\n",
      "1592/1592 - 25s - loss: 0.1359 - accuracy: 0.9506 - val_loss: 0.4257 - val_accuracy: 0.8711 - 25s/epoch - 16ms/step\n",
      "Epoch 258/400\n",
      "1592/1592 - 25s - loss: 0.1356 - accuracy: 0.9508 - val_loss: 0.4288 - val_accuracy: 0.8738 - 25s/epoch - 16ms/step\n",
      "Epoch 259/400\n",
      "1592/1592 - 25s - loss: 0.1352 - accuracy: 0.9513 - val_loss: 0.4342 - val_accuracy: 0.8728 - 25s/epoch - 16ms/step\n",
      "Epoch 260/400\n",
      "1592/1592 - 25s - loss: 0.1347 - accuracy: 0.9513 - val_loss: 0.4311 - val_accuracy: 0.8734 - 25s/epoch - 16ms/step\n",
      "Epoch 261/400\n",
      "1592/1592 - 25s - loss: 0.1334 - accuracy: 0.9517 - val_loss: 0.4309 - val_accuracy: 0.8720 - 25s/epoch - 16ms/step\n",
      "Epoch 262/400\n",
      "1592/1592 - 25s - loss: 0.1338 - accuracy: 0.9516 - val_loss: 0.4417 - val_accuracy: 0.8698 - 25s/epoch - 16ms/step\n",
      "Epoch 263/400\n",
      "1592/1592 - 25s - loss: 0.1330 - accuracy: 0.9515 - val_loss: 0.4438 - val_accuracy: 0.8706 - 25s/epoch - 16ms/step\n",
      "Epoch 264/400\n",
      "1592/1592 - 25s - loss: 0.1325 - accuracy: 0.9519 - val_loss: 0.4447 - val_accuracy: 0.8726 - 25s/epoch - 16ms/step\n",
      "Epoch 265/400\n",
      "1592/1592 - 25s - loss: 0.1324 - accuracy: 0.9518 - val_loss: 0.4359 - val_accuracy: 0.8739 - 25s/epoch - 16ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 266/400\n",
      "1592/1592 - 25s - loss: 0.1326 - accuracy: 0.9515 - val_loss: 0.4504 - val_accuracy: 0.8705 - 25s/epoch - 16ms/step\n",
      "Epoch 267/400\n",
      "1592/1592 - 25s - loss: 0.1318 - accuracy: 0.9523 - val_loss: 0.4403 - val_accuracy: 0.8692 - 25s/epoch - 16ms/step\n",
      "Epoch 268/400\n",
      "1592/1592 - 25s - loss: 0.1318 - accuracy: 0.9521 - val_loss: 0.4416 - val_accuracy: 0.8711 - 25s/epoch - 16ms/step\n",
      "Epoch 269/400\n",
      "1592/1592 - 25s - loss: 0.1322 - accuracy: 0.9519 - val_loss: 0.4408 - val_accuracy: 0.8693 - 25s/epoch - 16ms/step\n",
      "Epoch 270/400\n",
      "1592/1592 - 25s - loss: 0.1311 - accuracy: 0.9525 - val_loss: 0.4435 - val_accuracy: 0.8687 - 25s/epoch - 16ms/step\n",
      "Epoch 271/400\n",
      "1592/1592 - 25s - loss: 0.1299 - accuracy: 0.9526 - val_loss: 0.4422 - val_accuracy: 0.8710 - 25s/epoch - 16ms/step\n",
      "Epoch 272/400\n",
      "1592/1592 - 25s - loss: 0.1291 - accuracy: 0.9529 - val_loss: 0.4488 - val_accuracy: 0.8705 - 25s/epoch - 16ms/step\n",
      "Epoch 273/400\n",
      "1592/1592 - 25s - loss: 0.1298 - accuracy: 0.9524 - val_loss: 0.4483 - val_accuracy: 0.8714 - 25s/epoch - 16ms/step\n",
      "Epoch 274/400\n",
      "1592/1592 - 25s - loss: 0.1294 - accuracy: 0.9526 - val_loss: 0.4432 - val_accuracy: 0.8706 - 25s/epoch - 16ms/step\n",
      "Epoch 275/400\n",
      "1592/1592 - 25s - loss: 0.1288 - accuracy: 0.9535 - val_loss: 0.4524 - val_accuracy: 0.8695 - 25s/epoch - 16ms/step\n",
      "Epoch 276/400\n",
      "1592/1592 - 25s - loss: 0.1285 - accuracy: 0.9533 - val_loss: 0.4561 - val_accuracy: 0.8693 - 25s/epoch - 16ms/step\n",
      "Epoch 277/400\n",
      "1592/1592 - 25s - loss: 0.1290 - accuracy: 0.9532 - val_loss: 0.4562 - val_accuracy: 0.8708 - 25s/epoch - 16ms/step\n",
      "Epoch 278/400\n",
      "1592/1592 - 25s - loss: 0.1277 - accuracy: 0.9532 - val_loss: 0.4494 - val_accuracy: 0.8717 - 25s/epoch - 16ms/step\n",
      "Epoch 279/400\n",
      "1592/1592 - 25s - loss: 0.1284 - accuracy: 0.9536 - val_loss: 0.4733 - val_accuracy: 0.8659 - 25s/epoch - 16ms/step\n",
      "Epoch 280/400\n",
      "1592/1592 - 25s - loss: 0.1274 - accuracy: 0.9535 - val_loss: 0.4535 - val_accuracy: 0.8710 - 25s/epoch - 16ms/step\n",
      "Epoch 281/400\n",
      "1592/1592 - 25s - loss: 0.1265 - accuracy: 0.9541 - val_loss: 0.4636 - val_accuracy: 0.8706 - 25s/epoch - 16ms/step\n",
      "Epoch 282/400\n",
      "1592/1592 - 25s - loss: 0.1270 - accuracy: 0.9539 - val_loss: 0.4560 - val_accuracy: 0.8724 - 25s/epoch - 16ms/step\n",
      "Epoch 283/400\n",
      "1592/1592 - 25s - loss: 0.1263 - accuracy: 0.9543 - val_loss: 0.4487 - val_accuracy: 0.8703 - 25s/epoch - 16ms/step\n",
      "Epoch 284/400\n",
      "1592/1592 - 25s - loss: 0.1266 - accuracy: 0.9540 - val_loss: 0.4692 - val_accuracy: 0.8667 - 25s/epoch - 16ms/step\n",
      "Epoch 285/400\n",
      "1592/1592 - 25s - loss: 0.1252 - accuracy: 0.9546 - val_loss: 0.4592 - val_accuracy: 0.8660 - 25s/epoch - 16ms/step\n",
      "Epoch 286/400\n",
      "1592/1592 - 25s - loss: 0.1257 - accuracy: 0.9544 - val_loss: 0.4647 - val_accuracy: 0.8671 - 25s/epoch - 16ms/step\n",
      "Epoch 287/400\n",
      "1592/1592 - 25s - loss: 0.1253 - accuracy: 0.9544 - val_loss: 0.4537 - val_accuracy: 0.8708 - 25s/epoch - 16ms/step\n",
      "Epoch 288/400\n",
      "1592/1592 - 25s - loss: 0.1251 - accuracy: 0.9546 - val_loss: 0.4587 - val_accuracy: 0.8705 - 25s/epoch - 16ms/step\n",
      "Epoch 289/400\n",
      "1592/1592 - 25s - loss: 0.1246 - accuracy: 0.9547 - val_loss: 0.4652 - val_accuracy: 0.8691 - 25s/epoch - 16ms/step\n",
      "Epoch 290/400\n",
      "1592/1592 - 25s - loss: 0.1234 - accuracy: 0.9550 - val_loss: 0.4632 - val_accuracy: 0.8715 - 25s/epoch - 16ms/step\n",
      "Epoch 291/400\n",
      "1592/1592 - 25s - loss: 0.1222 - accuracy: 0.9552 - val_loss: 0.4576 - val_accuracy: 0.8682 - 25s/epoch - 16ms/step\n",
      "Epoch 292/400\n",
      "1592/1592 - 25s - loss: 0.1225 - accuracy: 0.9554 - val_loss: 0.4526 - val_accuracy: 0.8720 - 25s/epoch - 16ms/step\n",
      "Epoch 293/400\n",
      "1592/1592 - 25s - loss: 0.1230 - accuracy: 0.9554 - val_loss: 0.4685 - val_accuracy: 0.8688 - 25s/epoch - 16ms/step\n",
      "Epoch 294/400\n",
      "1592/1592 - 25s - loss: 0.1226 - accuracy: 0.9553 - val_loss: 0.4873 - val_accuracy: 0.8659 - 25s/epoch - 16ms/step\n",
      "Epoch 295/400\n",
      "1592/1592 - 25s - loss: 0.1227 - accuracy: 0.9556 - val_loss: 0.4717 - val_accuracy: 0.8674 - 25s/epoch - 16ms/step\n",
      "Epoch 296/400\n",
      "1592/1592 - 25s - loss: 0.1203 - accuracy: 0.9560 - val_loss: 0.4676 - val_accuracy: 0.8702 - 25s/epoch - 16ms/step\n",
      "Epoch 297/400\n",
      "1592/1592 - 25s - loss: 0.1222 - accuracy: 0.9558 - val_loss: 0.4866 - val_accuracy: 0.8640 - 25s/epoch - 16ms/step\n",
      "Epoch 298/400\n",
      "1592/1592 - 25s - loss: 0.1206 - accuracy: 0.9561 - val_loss: 0.4700 - val_accuracy: 0.8732 - 25s/epoch - 16ms/step\n",
      "Epoch 299/400\n",
      "1592/1592 - 25s - loss: 0.1213 - accuracy: 0.9558 - val_loss: 0.4669 - val_accuracy: 0.8682 - 25s/epoch - 16ms/step\n",
      "Epoch 300/400\n",
      "1592/1592 - 25s - loss: 0.1200 - accuracy: 0.9563 - val_loss: 0.4713 - val_accuracy: 0.8710 - 25s/epoch - 16ms/step\n",
      "Epoch 301/400\n",
      "1592/1592 - 25s - loss: 0.1194 - accuracy: 0.9566 - val_loss: 0.4698 - val_accuracy: 0.8669 - 25s/epoch - 16ms/step\n",
      "Epoch 302/400\n",
      "1592/1592 - 25s - loss: 0.1192 - accuracy: 0.9565 - val_loss: 0.4652 - val_accuracy: 0.8693 - 25s/epoch - 16ms/step\n",
      "Epoch 303/400\n",
      "1592/1592 - 25s - loss: 0.1199 - accuracy: 0.9559 - val_loss: 0.4627 - val_accuracy: 0.8693 - 25s/epoch - 16ms/step\n",
      "Epoch 304/400\n",
      "1592/1592 - 25s - loss: 0.1191 - accuracy: 0.9568 - val_loss: 0.4696 - val_accuracy: 0.8695 - 25s/epoch - 16ms/step\n",
      "Epoch 305/400\n",
      "1592/1592 - 25s - loss: 0.1188 - accuracy: 0.9566 - val_loss: 0.4871 - val_accuracy: 0.8680 - 25s/epoch - 16ms/step\n",
      "Epoch 306/400\n",
      "1592/1592 - 25s - loss: 0.1187 - accuracy: 0.9570 - val_loss: 0.4705 - val_accuracy: 0.8699 - 25s/epoch - 16ms/step\n",
      "Epoch 307/400\n",
      "1592/1592 - 25s - loss: 0.1184 - accuracy: 0.9564 - val_loss: 0.4810 - val_accuracy: 0.8682 - 25s/epoch - 16ms/step\n",
      "Epoch 308/400\n",
      "1592/1592 - 25s - loss: 0.1183 - accuracy: 0.9570 - val_loss: 0.4787 - val_accuracy: 0.8696 - 25s/epoch - 16ms/step\n",
      "Epoch 309/400\n",
      "1592/1592 - 25s - loss: 0.1170 - accuracy: 0.9575 - val_loss: 0.4879 - val_accuracy: 0.8652 - 25s/epoch - 16ms/step\n",
      "Epoch 310/400\n",
      "1592/1592 - 25s - loss: 0.1168 - accuracy: 0.9577 - val_loss: 0.4858 - val_accuracy: 0.8672 - 25s/epoch - 16ms/step\n",
      "Epoch 311/400\n",
      "1592/1592 - 25s - loss: 0.1158 - accuracy: 0.9581 - val_loss: 0.4813 - val_accuracy: 0.8641 - 25s/epoch - 16ms/step\n",
      "Epoch 312/400\n",
      "1592/1592 - 25s - loss: 0.1173 - accuracy: 0.9576 - val_loss: 0.4821 - val_accuracy: 0.8657 - 25s/epoch - 16ms/step\n",
      "Epoch 313/400\n",
      "1592/1592 - 25s - loss: 0.1155 - accuracy: 0.9582 - val_loss: 0.4756 - val_accuracy: 0.8690 - 25s/epoch - 16ms/step\n",
      "Epoch 314/400\n",
      "1592/1592 - 25s - loss: 0.1157 - accuracy: 0.9580 - val_loss: 0.4908 - val_accuracy: 0.8671 - 25s/epoch - 16ms/step\n",
      "Epoch 315/400\n",
      "1592/1592 - 25s - loss: 0.1165 - accuracy: 0.9576 - val_loss: 0.4896 - val_accuracy: 0.8675 - 25s/epoch - 16ms/step\n",
      "Epoch 316/400\n",
      "1592/1592 - 25s - loss: 0.1145 - accuracy: 0.9581 - val_loss: 0.4801 - val_accuracy: 0.8702 - 25s/epoch - 16ms/step\n",
      "Epoch 317/400\n",
      "1592/1592 - 25s - loss: 0.1142 - accuracy: 0.9581 - val_loss: 0.4960 - val_accuracy: 0.8677 - 25s/epoch - 16ms/step\n",
      "Epoch 318/400\n",
      "1592/1592 - 25s - loss: 0.1142 - accuracy: 0.9585 - val_loss: 0.4984 - val_accuracy: 0.8680 - 25s/epoch - 16ms/step\n",
      "Epoch 319/400\n",
      "1592/1592 - 25s - loss: 0.1140 - accuracy: 0.9587 - val_loss: 0.4898 - val_accuracy: 0.8660 - 25s/epoch - 16ms/step\n",
      "Epoch 320/400\n",
      "1592/1592 - 25s - loss: 0.1141 - accuracy: 0.9587 - val_loss: 0.4811 - val_accuracy: 0.8691 - 25s/epoch - 16ms/step\n",
      "Epoch 321/400\n",
      "1592/1592 - 25s - loss: 0.1157 - accuracy: 0.9577 - val_loss: 0.4918 - val_accuracy: 0.8680 - 25s/epoch - 16ms/step\n",
      "Epoch 322/400\n",
      "1592/1592 - 25s - loss: 0.1131 - accuracy: 0.9588 - val_loss: 0.4845 - val_accuracy: 0.8655 - 25s/epoch - 16ms/step\n",
      "Epoch 323/400\n",
      "1592/1592 - 25s - loss: 0.1122 - accuracy: 0.9594 - val_loss: 0.4967 - val_accuracy: 0.8678 - 25s/epoch - 16ms/step\n",
      "Epoch 324/400\n",
      "1592/1592 - 25s - loss: 0.1116 - accuracy: 0.9594 - val_loss: 0.4945 - val_accuracy: 0.8669 - 25s/epoch - 16ms/step\n",
      "Epoch 325/400\n",
      "1592/1592 - 25s - loss: 0.1131 - accuracy: 0.9588 - val_loss: 0.4972 - val_accuracy: 0.8692 - 25s/epoch - 16ms/step\n",
      "Epoch 326/400\n",
      "1592/1592 - 25s - loss: 0.1127 - accuracy: 0.9592 - val_loss: 0.4987 - val_accuracy: 0.8644 - 25s/epoch - 16ms/step\n",
      "Epoch 327/400\n",
      "1592/1592 - 25s - loss: 0.1128 - accuracy: 0.9591 - val_loss: 0.5041 - val_accuracy: 0.8653 - 25s/epoch - 16ms/step\n",
      "Epoch 328/400\n",
      "1592/1592 - 25s - loss: 0.1112 - accuracy: 0.9596 - val_loss: 0.4972 - val_accuracy: 0.8662 - 25s/epoch - 16ms/step\n",
      "Epoch 329/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1592/1592 - 25s - loss: 0.1107 - accuracy: 0.9596 - val_loss: 0.4933 - val_accuracy: 0.8693 - 25s/epoch - 16ms/step\n",
      "Epoch 330/400\n",
      "1592/1592 - 25s - loss: 0.1109 - accuracy: 0.9594 - val_loss: 0.5059 - val_accuracy: 0.8633 - 25s/epoch - 16ms/step\n",
      "Epoch 331/400\n",
      "1592/1592 - 25s - loss: 0.1108 - accuracy: 0.9598 - val_loss: 0.5021 - val_accuracy: 0.8661 - 25s/epoch - 16ms/step\n",
      "Epoch 332/400\n",
      "1592/1592 - 25s - loss: 0.1108 - accuracy: 0.9597 - val_loss: 0.4995 - val_accuracy: 0.8670 - 25s/epoch - 16ms/step\n",
      "Epoch 333/400\n",
      "1592/1592 - 25s - loss: 0.1101 - accuracy: 0.9603 - val_loss: 0.5013 - val_accuracy: 0.8678 - 25s/epoch - 16ms/step\n",
      "Epoch 334/400\n",
      "1592/1592 - 25s - loss: 0.1104 - accuracy: 0.9597 - val_loss: 0.4990 - val_accuracy: 0.8631 - 25s/epoch - 16ms/step\n",
      "Epoch 335/400\n",
      "1592/1592 - 25s - loss: 0.1087 - accuracy: 0.9603 - val_loss: 0.5022 - val_accuracy: 0.8664 - 25s/epoch - 16ms/step\n",
      "Epoch 336/400\n",
      "1592/1592 - 25s - loss: 0.1088 - accuracy: 0.9604 - val_loss: 0.5502 - val_accuracy: 0.8492 - 25s/epoch - 16ms/step\n",
      "Epoch 337/400\n",
      "1592/1592 - 25s - loss: 0.1080 - accuracy: 0.9608 - val_loss: 0.5032 - val_accuracy: 0.8655 - 25s/epoch - 16ms/step\n",
      "Epoch 338/400\n",
      "1592/1592 - 25s - loss: 0.1079 - accuracy: 0.9610 - val_loss: 0.5066 - val_accuracy: 0.8655 - 25s/epoch - 16ms/step\n",
      "Epoch 339/400\n",
      "1592/1592 - 25s - loss: 0.1094 - accuracy: 0.9599 - val_loss: 0.5036 - val_accuracy: 0.8676 - 25s/epoch - 16ms/step\n",
      "Epoch 340/400\n",
      "1592/1592 - 25s - loss: 0.1072 - accuracy: 0.9609 - val_loss: 0.5212 - val_accuracy: 0.8684 - 25s/epoch - 16ms/step\n",
      "Epoch 341/400\n",
      "1592/1592 - 25s - loss: 0.1087 - accuracy: 0.9605 - val_loss: 0.5079 - val_accuracy: 0.8630 - 25s/epoch - 16ms/step\n",
      "Epoch 342/400\n",
      "1592/1592 - 25s - loss: 0.1073 - accuracy: 0.9608 - val_loss: 0.5153 - val_accuracy: 0.8674 - 25s/epoch - 16ms/step\n",
      "Epoch 343/400\n",
      "1592/1592 - 25s - loss: 0.1068 - accuracy: 0.9614 - val_loss: 0.5071 - val_accuracy: 0.8658 - 25s/epoch - 16ms/step\n",
      "Epoch 344/400\n",
      "1592/1592 - 25s - loss: 0.1069 - accuracy: 0.9610 - val_loss: 0.5051 - val_accuracy: 0.8697 - 25s/epoch - 16ms/step\n",
      "Epoch 345/400\n",
      "1592/1592 - 25s - loss: 0.1066 - accuracy: 0.9615 - val_loss: 0.5230 - val_accuracy: 0.8665 - 25s/epoch - 16ms/step\n",
      "Epoch 346/400\n",
      "1592/1592 - 25s - loss: 0.1063 - accuracy: 0.9612 - val_loss: 0.5195 - val_accuracy: 0.8649 - 25s/epoch - 16ms/step\n",
      "Epoch 347/400\n",
      "1592/1592 - 25s - loss: 0.1069 - accuracy: 0.9611 - val_loss: 0.5146 - val_accuracy: 0.8676 - 25s/epoch - 16ms/step\n",
      "Epoch 348/400\n",
      "1592/1592 - 25s - loss: 0.1061 - accuracy: 0.9617 - val_loss: 0.5100 - val_accuracy: 0.8673 - 25s/epoch - 16ms/step\n",
      "Epoch 349/400\n",
      "1592/1592 - 25s - loss: 0.1066 - accuracy: 0.9612 - val_loss: 0.5145 - val_accuracy: 0.8653 - 25s/epoch - 16ms/step\n",
      "Epoch 350/400\n",
      "1592/1592 - 25s - loss: 0.1053 - accuracy: 0.9614 - val_loss: 0.5331 - val_accuracy: 0.8609 - 25s/epoch - 16ms/step\n",
      "Epoch 351/400\n",
      "1592/1592 - 25s - loss: 0.1042 - accuracy: 0.9622 - val_loss: 0.5195 - val_accuracy: 0.8674 - 25s/epoch - 16ms/step\n",
      "Epoch 352/400\n",
      "1592/1592 - 25s - loss: 0.1051 - accuracy: 0.9618 - val_loss: 0.5274 - val_accuracy: 0.8660 - 25s/epoch - 16ms/step\n",
      "Epoch 353/400\n",
      "1592/1592 - 25s - loss: 0.1052 - accuracy: 0.9616 - val_loss: 0.5154 - val_accuracy: 0.8661 - 25s/epoch - 16ms/step\n",
      "Epoch 354/400\n",
      "1592/1592 - 25s - loss: 0.1038 - accuracy: 0.9623 - val_loss: 0.5210 - val_accuracy: 0.8658 - 25s/epoch - 16ms/step\n",
      "Epoch 355/400\n",
      "1592/1592 - 25s - loss: 0.1038 - accuracy: 0.9622 - val_loss: 0.5159 - val_accuracy: 0.8668 - 25s/epoch - 16ms/step\n",
      "Epoch 356/400\n",
      "1592/1592 - 25s - loss: 0.1036 - accuracy: 0.9623 - val_loss: 0.5227 - val_accuracy: 0.8617 - 25s/epoch - 16ms/step\n",
      "Epoch 357/400\n",
      "1592/1592 - 25s - loss: 0.1033 - accuracy: 0.9623 - val_loss: 0.5301 - val_accuracy: 0.8665 - 25s/epoch - 16ms/step\n",
      "Epoch 358/400\n",
      "1592/1592 - 25s - loss: 0.1025 - accuracy: 0.9626 - val_loss: 0.5412 - val_accuracy: 0.8616 - 25s/epoch - 16ms/step\n",
      "Epoch 359/400\n",
      "1592/1592 - 25s - loss: 0.1015 - accuracy: 0.9632 - val_loss: 0.5273 - val_accuracy: 0.8633 - 25s/epoch - 16ms/step\n",
      "Epoch 360/400\n",
      "1592/1592 - 25s - loss: 0.1031 - accuracy: 0.9625 - val_loss: 0.5290 - val_accuracy: 0.8643 - 25s/epoch - 16ms/step\n",
      "Epoch 361/400\n",
      "1592/1592 - 25s - loss: 0.1017 - accuracy: 0.9628 - val_loss: 0.5333 - val_accuracy: 0.8676 - 25s/epoch - 16ms/step\n",
      "Epoch 362/400\n",
      "1592/1592 - 25s - loss: 0.1018 - accuracy: 0.9630 - val_loss: 0.5322 - val_accuracy: 0.8623 - 25s/epoch - 16ms/step\n",
      "Epoch 363/400\n",
      "1592/1592 - 25s - loss: 0.1014 - accuracy: 0.9630 - val_loss: 0.5296 - val_accuracy: 0.8643 - 25s/epoch - 16ms/step\n",
      "Epoch 364/400\n",
      "1592/1592 - 25s - loss: 0.1017 - accuracy: 0.9634 - val_loss: 0.5338 - val_accuracy: 0.8671 - 25s/epoch - 16ms/step\n",
      "Epoch 365/400\n",
      "1592/1592 - 25s - loss: 0.1012 - accuracy: 0.9630 - val_loss: 0.5333 - val_accuracy: 0.8666 - 25s/epoch - 16ms/step\n",
      "Epoch 366/400\n",
      "1592/1592 - 25s - loss: 0.1006 - accuracy: 0.9638 - val_loss: 0.5344 - val_accuracy: 0.8645 - 25s/epoch - 16ms/step\n",
      "Epoch 367/400\n",
      "1592/1592 - 25s - loss: 0.1006 - accuracy: 0.9639 - val_loss: 0.5331 - val_accuracy: 0.8591 - 25s/epoch - 16ms/step\n",
      "Epoch 368/400\n",
      "1592/1592 - 25s - loss: 0.1012 - accuracy: 0.9634 - val_loss: 0.5191 - val_accuracy: 0.8649 - 25s/epoch - 16ms/step\n",
      "Epoch 369/400\n",
      "1592/1592 - 25s - loss: 0.1002 - accuracy: 0.9636 - val_loss: 0.5297 - val_accuracy: 0.8662 - 25s/epoch - 16ms/step\n",
      "Epoch 370/400\n",
      "1592/1592 - 25s - loss: 0.1000 - accuracy: 0.9635 - val_loss: 0.5384 - val_accuracy: 0.8673 - 25s/epoch - 16ms/step\n",
      "Epoch 371/400\n",
      "1592/1592 - 25s - loss: 0.1011 - accuracy: 0.9633 - val_loss: 0.5223 - val_accuracy: 0.8649 - 25s/epoch - 16ms/step\n",
      "Epoch 372/400\n",
      "1592/1592 - 25s - loss: 0.0996 - accuracy: 0.9635 - val_loss: 0.5408 - val_accuracy: 0.8671 - 25s/epoch - 16ms/step\n",
      "Epoch 373/400\n",
      "1592/1592 - 25s - loss: 0.0987 - accuracy: 0.9638 - val_loss: 0.5369 - val_accuracy: 0.8661 - 25s/epoch - 16ms/step\n",
      "Epoch 374/400\n",
      "1592/1592 - 25s - loss: 0.0988 - accuracy: 0.9641 - val_loss: 0.5356 - val_accuracy: 0.8656 - 25s/epoch - 16ms/step\n",
      "Epoch 375/400\n",
      "1592/1592 - 25s - loss: 0.0997 - accuracy: 0.9637 - val_loss: 0.5360 - val_accuracy: 0.8649 - 25s/epoch - 16ms/step\n",
      "Epoch 376/400\n",
      "1592/1592 - 25s - loss: 0.0977 - accuracy: 0.9645 - val_loss: 0.5468 - val_accuracy: 0.8639 - 25s/epoch - 16ms/step\n",
      "Epoch 377/400\n",
      "1592/1592 - 25s - loss: 0.0976 - accuracy: 0.9648 - val_loss: 0.5445 - val_accuracy: 0.8630 - 25s/epoch - 16ms/step\n",
      "Epoch 378/400\n",
      "1592/1592 - 25s - loss: 0.0981 - accuracy: 0.9644 - val_loss: 0.5522 - val_accuracy: 0.8629 - 25s/epoch - 16ms/step\n",
      "Epoch 379/400\n",
      "1592/1592 - 25s - loss: 0.0978 - accuracy: 0.9644 - val_loss: 0.5537 - val_accuracy: 0.8658 - 25s/epoch - 16ms/step\n",
      "Epoch 380/400\n",
      "1592/1592 - 25s - loss: 0.0974 - accuracy: 0.9647 - val_loss: 0.5394 - val_accuracy: 0.8655 - 25s/epoch - 16ms/step\n",
      "Epoch 381/400\n",
      "1592/1592 - 25s - loss: 0.0958 - accuracy: 0.9650 - val_loss: 0.5516 - val_accuracy: 0.8658 - 25s/epoch - 16ms/step\n",
      "Epoch 382/400\n",
      "1592/1592 - 25s - loss: 0.0976 - accuracy: 0.9645 - val_loss: 0.5528 - val_accuracy: 0.8607 - 25s/epoch - 16ms/step\n",
      "Epoch 383/400\n",
      "1592/1592 - 25s - loss: 0.0980 - accuracy: 0.9642 - val_loss: 0.5384 - val_accuracy: 0.8655 - 25s/epoch - 16ms/step\n",
      "Epoch 384/400\n",
      "1592/1592 - 25s - loss: 0.0965 - accuracy: 0.9649 - val_loss: 0.5420 - val_accuracy: 0.8605 - 25s/epoch - 16ms/step\n",
      "Epoch 385/400\n",
      "1592/1592 - 25s - loss: 0.0961 - accuracy: 0.9647 - val_loss: 0.5772 - val_accuracy: 0.8624 - 25s/epoch - 16ms/step\n",
      "Epoch 386/400\n",
      "1592/1592 - 25s - loss: 0.0968 - accuracy: 0.9647 - val_loss: 0.5502 - val_accuracy: 0.8620 - 25s/epoch - 16ms/step\n",
      "Epoch 387/400\n",
      "1592/1592 - 25s - loss: 0.0955 - accuracy: 0.9656 - val_loss: 0.5561 - val_accuracy: 0.8642 - 25s/epoch - 16ms/step\n",
      "Epoch 388/400\n",
      "1592/1592 - 25s - loss: 0.0961 - accuracy: 0.9650 - val_loss: 0.5548 - val_accuracy: 0.8654 - 25s/epoch - 16ms/step\n",
      "Epoch 389/400\n",
      "1592/1592 - 25s - loss: 0.0959 - accuracy: 0.9650 - val_loss: 0.5456 - val_accuracy: 0.8649 - 25s/epoch - 16ms/step\n",
      "Epoch 390/400\n",
      "1592/1592 - 25s - loss: 0.0943 - accuracy: 0.9658 - val_loss: 0.5544 - val_accuracy: 0.8658 - 25s/epoch - 16ms/step\n",
      "Epoch 391/400\n",
      "1592/1592 - 25s - loss: 0.0941 - accuracy: 0.9657 - val_loss: 0.5507 - val_accuracy: 0.8640 - 25s/epoch - 16ms/step\n",
      "Epoch 392/400\n",
      "1592/1592 - 25s - loss: 0.0958 - accuracy: 0.9653 - val_loss: 0.5649 - val_accuracy: 0.8640 - 25s/epoch - 16ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/400\n",
      "1592/1592 - 25s - loss: 0.0961 - accuracy: 0.9649 - val_loss: 0.5565 - val_accuracy: 0.8657 - 25s/epoch - 16ms/step\n",
      "Epoch 394/400\n",
      "1592/1592 - 25s - loss: 0.0936 - accuracy: 0.9662 - val_loss: 0.5510 - val_accuracy: 0.8655 - 25s/epoch - 16ms/step\n",
      "Epoch 395/400\n",
      "1592/1592 - 25s - loss: 0.0938 - accuracy: 0.9661 - val_loss: 0.5532 - val_accuracy: 0.8668 - 25s/epoch - 16ms/step\n",
      "Epoch 396/400\n",
      "1592/1592 - 25s - loss: 0.0942 - accuracy: 0.9656 - val_loss: 0.5692 - val_accuracy: 0.8633 - 25s/epoch - 16ms/step\n",
      "Epoch 397/400\n",
      "1592/1592 - 25s - loss: 0.0932 - accuracy: 0.9663 - val_loss: 0.5542 - val_accuracy: 0.8682 - 25s/epoch - 16ms/step\n",
      "Epoch 398/400\n",
      "1592/1592 - 25s - loss: 0.0914 - accuracy: 0.9666 - val_loss: 0.5660 - val_accuracy: 0.8615 - 25s/epoch - 16ms/step\n",
      "Epoch 399/400\n",
      "1592/1592 - 25s - loss: 0.0927 - accuracy: 0.9665 - val_loss: 0.5738 - val_accuracy: 0.8643 - 25s/epoch - 16ms/step\n",
      "Epoch 400/400\n",
      "1592/1592 - 25s - loss: 0.0942 - accuracy: 0.9660 - val_loss: 0.5569 - val_accuracy: 0.8647 - 25s/epoch - 16ms/step\n",
      "CPU times: user 3h 4min 35s, sys: 4min 12s, total: 3h 8min 47s\n",
      "Wall time: 2h 47min 9s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f37e43c65e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "\n",
    "deeplob.fit(new_x_train, trainY_CNN, validation_data=(new_x_val, valY_CNN), \n",
    "            epochs=400, batch_size=128, verbose=2, callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4359/4359 [==============================] - 16s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "deeplob.load_weights(checkpoint_filepath)\n",
    "pred = deeplob.predict(new_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.899260151410874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8934    0.9162    0.9046     47915\n",
      "           1     0.9028    0.8781    0.8903     48050\n",
      "           2     0.9021    0.9040    0.9030     43523\n",
      "\n",
      "    accuracy                         0.8993    139488\n",
      "   macro avg     0.8994    0.8994    0.8993    139488\n",
      "weighted avg     0.8993    0.8993    0.8992    139488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy_score:', accuracy_score(np.argmax(testY_CNN, axis=1), np.argmax(pred, axis=1)))\n",
    "print(classification_report(np.argmax(testY_CNN, axis=1), np.argmax(pred, axis=1), digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
